{
  "agent_id": "coder2",
  "task_id": "task_5",
  "files": [
    {
      "name": "benchmarks.py",
      "purpose": "Benchmarking utilities",
      "priority": "low"
    },
    {
      "name": "utils.py",
      "purpose": "Utility functions",
      "priority": "low"
    }
  ],
  "project_info": {
    "project_name": "enhanced_cs.LG_2509.04430v1_Unveiling_the_Role_of_Data_Uncertainty_in_Tabular_",
    "project_type": "optimization",
    "description": "Enhanced AI project based on cs.LG_2509.04430v1_Unveiling-the-Role-of-Data-Uncertainty-in-Tabular- with content analysis. Detected project type: optimization (confidence score: 6 matches).",
    "key_algorithms": [
      "Estimation",
      "Like",
      "Tabular",
      "Learning",
      "Basic",
      "Dataset",
      "Embeddings",
      "All",
      "Tabm",
      "Estimator"
    ],
    "main_libraries": [
      "torch",
      "numpy",
      "pandas"
    ]
  },
  "paper_content": "PDF: cs.LG_2509.04430v1_Unveiling-the-Role-of-Data-Uncertainty-in-Tabular-.pdf\nChunk: 1/1\n==================================================\n\n--- Page 1 ---\nPreprint\nUNVEILING THE ROLE OF DATA UNCERTAINTY\nINTABULAR DEEPLEARNING\nNikolay Kartashev\nHSE University, YandexIvan Rubachev\nYandex, HSE UniversityArtem Babenko\nYandex, HSE University\nABSTRACT\nRecent advancements in tabular deep learning have demonstrated exceptional\npractical performance, yet the field often lacks a clear understanding of why\nthese techniques actually succeed. To address this gap, our paper highlights the\nimportance of the concept of data uncertainty for explaining the effectiveness of\nthe recent tabular DL methods. In particular, we reveal that the success of many\nbeneficial design choices in tabular DL, such as numerical feature embeddings,\nretrieval-augmented models and advanced ensembling strategies, can be largely\nattributed to their implicit mechanisms for managing high data uncertainty. By\ndissecting these mechanisms, we provide a unifying understanding of the recent\nperformance improvements. Furthermore, the insights derived from this data-\nuncertainty perspective directly allowed us to develop more effective numerical\nfeature embeddings as an immediate practical outcome of our analysis. Overall,\nour work paves the way to foundational understanding of the benefits introduced\nby modern tabular methods that results in the concrete advancements of existing\ntechniques and outlines future research directions for tabular DL.\n1 I NTRODUCTION\nDeep learning for tabular data is experiencing rapid progress, with new models and training ap-\nproaches constantly improving performance across a wide range of tasks (Gorishniy et al., 2022;\nHollmann et al., 2023; Gorishniy et al., 2024; Ye et al., 2024; Holzm\u00fcller et al., 2024; Gorishniy\net al., 2025; Hollmann et al., 2025). However, a clear understanding of why the proposed techniques\nare effective mostly lags behind their empirical success. New methods are often introduced based\nprimarily on empirical observations or by repurposing ideas from other domains, often without a\nthorough investigation of their effectiveness within the tabular data context. This gap between perfor-\nmance and understanding can hinder the future progress, potentially leading to a more trial-and-error\nresearch style.\nIn this paper, we address this gap by leveraging the concept of data (aleatoric) uncertainty (Gal\net al., 2016) as an informative tool for analyzing and understanding the effectiveness of recent\ntabular DL methods. Our rough motivation to employ data uncertainty originates from the intuition\nthat, compared to computer vision or NLP, tabular problems often possess unobserved confounding\nvariables and inherent noise in target labels that makes it challenging for models \u2014 and even human\nexperts \u2014 to achieve perfect predictive accuracy due to irreducible noise or ambiguity. Furthermore,\nmuch indirect evidence also indicates high data uncertainty being a significant factor in tabular\nlearning. For instance, the critical reliance of tabular DL performance on early stopping hints at the\npresence of significant noise in the labels (Baek et al., 2024). While any single point above does\nnot strictly necessitate that data uncertainty is an important constituent of a typical tabular problem,\naccumulated evidence from them convinced us to take a closer look at this tool. Interestingly, in the\npreliminary experiments, we compared a simple MLP model to the leading GBDT implementation in\nterms of performance on datapoints with different data uncertainty. For several datasets, Figure 1\nshows that GBDTs perform much better specifically in the high data uncertainty niche, which\nindicates that the \u201cDL vs GBDT\u201d battle probably unfolds mostly there.\nIn light of this, we systematically investigate several influential findings from the tabular DL literature\n\u2014 specifically, numerical feature embeddings (Gorishniy et al., 2022), retrieval-augmented models\n(Ye et al., 2024), and advanced ensembling strategies (Gorishniy et al., 2025) \u2014 in terms of their\n1arXiv:2509.04430v1  [cs.LG]  4 Sep 2025\n\n--- Page 2 ---\nPreprint\n0 1000 2000 3000 40000.000.050.100.150.20\u2206MSE =MSE MLP\u2212MSE XGBoost\n\u2206MSE\nMSE MLPCalifornia Housing\n0 2000 40000.000.020.040.06\n\u2206MSEMSE MLPSberbank Housing\n0 20000 40000 600000.0000.0010.0020.003\n\u2206MSEMSE MLPMaps Routing\n0 10000 20000 30000 400000.00.20.40.6\n\u2206MSE\nMSE MLPWeather\n0.00.20.40.60.8\n\u22120.050.000.050.100.150.200.250.30\n\u22120.010.000.010.020.030.040.050.06\n0246\nMSE MLP\nlower data uncertainty \u2190Test Dataset Examples \u2192higher data uncertainty\nFigure 1: The performance differences measured by MSE between MLP and XGBoost are shown\nin blue, and absolute values of MSE for MLP are shown in brown. The figure has two separate\nvertical axes: the left ones correspond to \u2206MSE, and the right ones correspond to absolute MSE.\nDifferences are reported for each test example, sorted from left to right by increasing data uncertainty.\nOn four datasets, especially on Sberbank Housing and Maps Routing, MLP has significantly worse\nperformance compared to XGBoost on high data uncertainty points. On Weather, this phenomenon is\nmore subtle, but in the region of high uncertainty, the MSE difference still grows faster than MSE\nitself.\nability to handle data uncertainty. Our investigation reveals a compelling and consistent pattern:\na significant portion of these techniques\u2019 success can be attributed to their implicit yet effective\nmechanisms for managing datapoints characterized by high data uncertainty. In more practical\nterms, the techniques often appear to be disproportionately more beneficial on the highly uncertain\ndatapoints. To obtain a clearer understanding, for each technique we dissect the specific mechanisms\nthat enable the management of these challenging samples. As a direct practical outcome of our\nanalysis, we employ the proposed data-uncertainty viewpoint to develop a novel numerical feature\nembedding scheme that is more effective than existing alternatives.\nOverall, the main contributions of our paper are:\n\u2022We introduce data uncertainty as an important tool to analyze the performance of various\ntabular learning methods and demonstrate that it provides an informative viewpoint on the\nmethods\u2019 advantages.\n\u2022We explain the specific mechanism behind the effectiveness of several recent tabular DL\ntechniques, including numerical feature embeddings, retrieval-augmented models, and\nparameter-efficient ensembling.\n\u2022We leverage the insights from our uncertainty-driven analysis to design a new, more effective\nnumerical feature embedding scheme.\n2 R ELATED WORK\nTabular Learning. The field of tabular data modeling has seen a significant transformation in recent\nyears, with deep learning approaches increasingly challenging the long-held supremacy of traditional\n\u201cshallow\u201d decision tree-based ensembles, such as Gradient Boosting Decision Trees (GBDTs). In\nparticular, the most recent DL models (Gorishniy et al., 2024; Holzm\u00fcller et al., 2024; Ye et al., 2024;\nGorishniy et al., 2025; Hollmann et al., 2025) have compellingly demonstrated performance on par\nwith, or even higher, than that of leading GBDT implementations like CatBoost (Prokhorenkova\net al., 2018), LightGBM (Ke et al., 2017), and XGBoost (Chen & Guestrin, 2016). This practical\nsuccess of tabular DL is a consequence of recent research efforts on novel architectures (Gorishniy\net al., 2021; Somepalli et al., 2021; Holzm\u00fcller et al., 2024; Gorishniy et al., 2022; Ye et al., 2024;\nGorishniy et al., 2024; 2025), specialized regularizations and learning protocols (Bahri et al., 2021;\nRubachev et al., 2022; Jeffares et al., 2023; Thimonier et al., 2024). However, despite this plethora of\nempirically successful techniques, an understanding of the core principles behind their effectiveness\noften remains unclear, highlighting a need for deeper analysis of their underlying mechanisms and\ncomparative strengths.\nAnalysis in Tabular DL. Several recent papers also contribute to a deeper understanding of the\nstrengths and limitations of tabular DL methods. Grinsztajn et al. (2022) identifies the reasons why\n2\n\n--- Page 3 ---\nPreprint\ntabular DL can be inferior to GBDT methods on certain datasets and formulates the desiderata for\ntabular DL methods, in particular, the ability to model irregular target dependencies. McElfresh et al.\n(2023) analyses the properties of tabular datasets that can be indicative of whether DL or GBDT\nmodels should be preferred. Rubachev et al. (2025) re-evaluates a large number of recent design\nchoices in tabular DL on a more realistic benchmark and reveals that many of them are not robust to\na temporal train\u2013test shift. In contrast to these dataset-centric or technique-centric investigations, our\npaper proposes a more fine-grained sample-wise analysis, examining performance at the individual\ndatapoint resolution.\nUncertainty Estimation. Uncertainty is a core concept in machine learning, reflecting potential\ninaccuracies in model predictions (Gal et al., 2016). Our work concentrates on data (aleatoric)\nuncertainty, which is inherent to the data itself \u2014 typically arising from noise or randomness\nin the underlying process being modelled (e.g., noisy features or targets). Importantly, this type\nof uncertainty is independent of the specific model used and represents a fundamental limit on\npredictability for a given data point. However, while the underlying noise is fixed, models do differ in\nhow effectively they cope with it. As we show, different tabular DL models exhibit varying levels of\nrobustness to this inherent noise, meaning some are better than others at yielding robust predictions\ndespite the intrinsic ambiguity present in certain samples.\n3 P RELIMINARIES\nIn this section, we outline the core concepts and notation required to analyze how different tabular\ndeep learning approaches interact with data uncertainty.\nThe concept of data uncertainty arises when the target dependency is not deterministic, and instead\nthe relationship between features xand target variable yis set by a non-degenerate conditional\ndistribution p(y|x). This can occur for several reasons, for example, in some cases, the label-\ncollection procedure can be noisy due to mistakes of human annotators or due to imperfect sensors.\nIn other cases, features in the dataset do not strictly determine the target variable; for example, it is\nimpossible to know an exact temperature in a given city by its longitude and latitude alone. In these\ncases, the labels provided in a given dataset are samples from this conditional distribution p(y|x).\nThe distribution p(y|x)may have different characteristics for different x. For example, measure-\nments of a target quantity could be exact for one set of xand only an approximation for another. The\nconcept of data uncertainty is used to measure how \u201cspread out\u201d the distributions p(y|x)are for\ndifferent samples of the data.\nInformally, data uncertainty quantifies the inherent noise, particularly label noise, present in the\ndata. While the loss in performance that comes from label noise in the test data is irreducible, it has\nbeen shown (Tanaka et al., 2018) that when training on noisy labels, the performance of a model\ndecreases even when measured on a clean test set. Different approaches and models can be influenced\nby this decrease to a different degree, which gives rise to a phenomenon we study in this paper.\nOur analysis focuses on regression tasks, in which data uncertainty for sample iis defined as the\nvariance of the distribution p(yi|xi). In section 5, section 6, and section 7, we show how increases\nin performance for recent methods in tabular deep learning are disproportionately larger on samples\nwhere data uncertainty is higher.\n3.1 D ATA UNCERTAINTY ESTIMATION\nA large part of our analysis relies on the empirical estimates of data uncertainty. When estimating\ndata uncertainty, we assume the following probabilistic model:\nyi=f(xi) +eg(xi)\u00b7 N(0,1) (1)\nHere (xi, yi)represents a datapoint, where xiis the feature set and yiis the target variable. The\ndeterministic function f(xi)is the noiseless part of the target dependency, while e2\u00b7g(xi)represents\nthe data uncertainty1. To obtain our estimates of data uncertainty, we train a machine learning model\n1This parameterization ensures that data uncertainty values are always positive.\n3\n\n--- Page 4 ---\nPreprint\nto predict both (f(xi), g(xi))for any given datapoint xi. The model is trained by maximizing the\nlikelihood of the observed target values under a distribution N(f(xi), e2\u00b7g(xi)). This estimation\napproach aligns with the recent works (Duan et al., 2020; Malinin et al., 2021). In our experiments,\nwe use CatBoost models (Prokhorenkova et al., 2018) to estimate the data uncertainty values, though\nany suitable deep learning model could be employed as well.\nCrucially, we find that the predicted data uncertainty values e2\u00b7g(xi)are relatively stable regardless\nof the specific estimator model used. For instance, see Figure 2a which demonstrates the strong\ncorrelations of uncertainty estimates produced by CatBoost and MLP on the California Housing,\nMaps Routing and Weather datasets. Moreover, the effects we analyze in section 5, section 6 and\nsection 7 stay the same regardless of which uncertainty estimation method we use, as shown in\nAppendix H.\nTo further confirm the reliability of our empirical data uncertainty estimates, we generate a synthetic\ndataset where both functions f(\u00b7)andg(\u00b7)from Equation 1 are randomly initialized MLPs. Figure 2b\nshows that the uncertainty values predicted by CatBoost closely match the ground-truth uncertainty\nvalues on this synthetic data. Moreover, we compare different tabular DL methods on datasets\ndescribed in subsection 4.2 and subsection 4.1 and demonstrate that an increase in performance\ncoincides with high data uncertainty even when the true values of data uncertainty are known and no\nestimation is used in the analysis.\n\u22126\u22124\u22122 0\u22126\u22124\u221220MLP Data Uncertaintya) California Housing\n\u22123\u22122\u22121 0\u22123\u22122\u221210Maps Routing\n\u22124\u22123\u22122\u22121 0\u22124\u22123\u22122\u221210Weather\n\u22124\u22122 0 2\nCatBoost Data Uncertainty\u22124\u2212202Ground Truth Data Uncertaintyb) Synthetic Dataset\nCatBoost Data Uncertainty\nFigure 2: a)The scatterplots show a high correlation between the log-transformed data uncertainty\nestimates from CatBoost and an MLP. b)The scatterplot shows the relationship between CatBoost\u2019s\nlog-estimated data uncertainty and the logarithms of the true data uncertainty values used for target\nsampling in the controlled synthetic experiment.\nTo analyze how various tabular DL methods perform on datapoints with different levels of data\nuncertainty, we draw uncertainty plots as follows. First, we obtain an estimate of data uncertainty\nfor each test sample in the dataset as described above. Then, test datapoints are sorted by increasing\nvalues of their estimated data uncertainty (or true data uncertainty for the synthetic dataset described\nin subsection 4.1). For each datapoint, we then compute the performance (in terms of Mean Squared\nError) of the simple MLP model and the method whose behavior we aim to analyze. Then, for\nvisualization purposes, we additionally smooth the resulting curve (see the details in Appendix B).\nAs an illustrative example, Figure 1 shows the uncertainty plot that compares MLP and XGBoost\non several datasets and reveals that MLP has much worse performance on datapoints of high data\nuncertainty.\n4 S YNTHETIC DATA\nFor real datasets, it is not entirely clear whether our estimation of data uncertainty reliably represents\nthe true data uncertainty. For this reason, we first use synthetic datasets to demonstrate how the\nperformance of several tabular DL methods changes at different levels of data uncertainty.\n4.1 S YNTHETIC DATASET WITH DATA UNCERTAINTY PARAMETERIZED BY AN MLP\nThe first dataset we use is obtained in the following way. First, we perform i.i.d. sampling from the\n20-dimensional standard Gaussian distribution to obtain the feature vectors xi. Then, we produce the\ntarget variables as f(xi) +eg(xi)\u00b7 N(0,1), where both f(\u00b7)andg(\u00b7)are parameterized as randomly\ninitialized MLPs. As a result of this procedure, we obtain a dataset for which data uncertainty exists\nand we know its true values for each sample. For full details regarding the creation of this dataset,\nsee Appendix F.\n4\n\n--- Page 5 ---\nPreprint\nFirst, using this dataset, in Figure 2b we show that when estimating data uncertainty with CatBoost, the\nobtained estimates are higly correlated with the true values. Moreover, in Figure 3, we demonstrate\nthat when using true data uncertainty, MLP-PLR, ModernNCA and TabM still show increased\nperformance compared to a simple MLP on high data uncertainty region of the data.\n0 1000 2000 3000 4000 5000\u22120.0050.0000.0050.0100.0150.020\u2206MSE =MSE MLP\u2212MSE Model\u2206MSE MLP\u2212PLR\n0 1000 2000 3000 4000 5000\u2206MSE ModernNCA\n0 1000 2000 3000 4000 5000\u2206MSE TabM\nLower Data Uncertainty \u2190Test Dataset Examples \u2192Higher Data Uncertainty\nFigure 3: This figure reports performance differences on the synthetic dataset described in this\nsubsection. We report differences in MSE between MLP and each of MLP-PLR, ModernNCA and\nTabM. Differences are reported for each test example, sorted from left to right by increasing true data\nuncertainty.\n4.2 S AW-LIKE 2D SYNTHETIC DATASET\nf(x) eg(x)\n0 1\nx10246810x2\n01\n051015\neg(x2)0246810x2\nFigure 4: The plots show visualization of\nthe synthetic data generation process used in\nsubsection 4.2. The left plot shows the func-\ntionf(x)in color, while the right plot shows\neg(x)on the x-axis. Targets yare generated\nasy=f(x) +eg(x)\u00b7 N(0,1).In the previous subsection, we demonstrated that the\ntrue values of data uncertainty are correlated with in-\ncreases in the performance of numerical embeddings,\nModernNCA, and TabM. As an additional illustra-\ntion, in this section, we visualize this behavior for the\n2Ddataset presented in Figure 4.\nThe data were generated as follows: objects\nxiare randomly and uniformly sampled from\na two-dimensional rectangle with vertices\n(0,0),(1,0),(1,10),(0,10). We then construct a\nsaw-like separation line, to the left of which the clean\ntargets fiare set to 1, and to the right of which the\nclean targets fiare 0, as shown in Figure 4. After\nthat step, Gaussian noise with standard deviation\neg(x)=x6\n2\n62500is added to the targets, where eg(x)\ndepends only on the vertical position of xand grows\nas its value changes from 0 to 10, as also visualized\non Figure 4. The final targets yiare produced as\nyi=fi+eg(xi)\u00b7 N(0,1). We use 80,000 training\ndata points and 10,000 validation and test data points each. For the specifics on dataset generation,\nsee Appendix D. Figure 5 demonstrates the predictions of the simple MLP model, as well as its\nfollowing modifications:\n1.MLP-LRLR \u2014 an MLP model augmented with learned numerical feature embeddings,\nproposed in Gorishniy et al. (2022).\n2.ModernNCA (Ye et al., 2024) \u2014 a retrieval-based model that consists of an MLP backbone\nfollowed by a kNN-like layer, producing a prediction by aggregating targets of training\ndatapoints.\n3. Deep Ensembles \u2014 the average prediction of five independently trained MLP models.\n4.TabM (Gorishniy et al., 2025) \u2014 a recent model that imitates an ensemble of MLPs in a\nparameter-efficient manner.\n5\n\n--- Page 6 ---\nPreprint\nWe provide the exact descriptions of the hyperparameter tuning for each model in Appendix E.\nFrom Figure 5, we see that there are almost no differences in performance between Deep Ensembles\nand MLP on this dataset. Meanwhile, MLP-LRLR, ModernNCA and TabM show substantially\nimproved performance in the regions of high data uncertainty \u2013 that is, the inner logic of these\ntechniques somehow allows them to manage uncertain regions of the dataset better. Further in the\npaper, section 5, section 6, and section 7 analyze the mechanisms behind each model in more detail.\n0 10246810x2MLP\n0 10246810Deep Ensemble\n0 10246810ModernNCA\n0 10246810TabM\n0 10246810MLP-LRLR\n0.00.20.40.60.81.0\nx1\nFigure 5: The plots show predictions of different models on the synthetic dataset described in sub-\nsection 4.2. While simple ensembling of MLPs does not change the results much, TabM noticeably\nincreases the quality of predictions. ModernNCA shows remarkable ability to recognize the underly-\ning data structure even with high levels of label noise, but it fails to model sharp changes in the target\neven at low levels of uncertainty. LRLR embeddings remarkably improve the quality of predictions\nin the regions of high data uncertainty in comparison with a simple MLP.\n4.3 SYNTHETIC VERSION OF THE CIFAR-10 DATASET WITH INCREASED DATA UNCERTAINTY\nTable 1: Accuracy of standard tabular DL methods on\ntwo versions of CIFAR-10. MLP outperforms both\nMLP-LRLR and ModernNCA on the standard CIFAR-\n10, while TabM and Deep Ensemble perform simi-\nlarly. On the Uncertain CIFAR-10, both MLP-LRLR\nand ModernNCA outperform MLP, while TabM out-\nperforms Deep Ensemble. In each category (Single\nModels and Ensembles), the best method and methods\nwith statistically insignificant differences from it are\nemphasized in bold.\nAccuracy \u2191\nMethod CIFAR-10 Uncertain CIFAR-10\nSingle Model Methods\nMLP 58.31\u00b10.27 47.54\u00b10.17\nMLP-LRLR 57.19 \u00b10.47 48.73\u00b10.23\nModernNCA 57.48 \u00b10.22 48.45\u00b10.30\nEmsembling Methods\nDeep Ensemble 60.92\u00b10.22 49.41\u00b10.20\nTabM 61.01\u00b10.25 50.45 \u00b10.19In this section, we construct another syn-\nthetic dataset based on the established\nCIFAR-10 dataset (Krizhevsky et al., 2009).\nTo do this, we use the intuition that data un-\ncertainty may increase when some features\nrelevant to the target variable are omitted\nfrom the dataset. Specifically, we take a\nstandard version of CIFAR-10, which has\n32\u00d732\u00d73 = 3072 features, and then ran-\ndomly choose 50features to keep, dropping\nall the other features from each sample in\nthe dataset. As a result of this operation,\nwe obtain a dataset we refer to as Uncertain\nCIFAR-10.\nWe then conduct experiments on both the\npruned and the original versions of CIFAR-\n10, using standard tabular DL methods. As\ncan be seen from Table 1, on the original\nversion of the dataset, MLP outperforms\nboth other single model methods (MLP-\nLRLR and ModernNCA), and in ensem-\nbling methods there is no difference between standard Deep Ensemble and TabM. However, on\nthe Uncertain CIFAR-10, TabM outperforms Deep Ensemble, while MLP-LRLR and ModernNCA\noutperform MLP. This experiment provides additional evidence of a relationship between data\nuncertainty and increases in performance for different tabular methods.\n6\n\n--- Page 7 ---\nPreprint\n5 E MBEDDINGS FOR NUMERICAL FEATURES\nRecent work by Gorishniy et al. (2022) demonstrated that, for tabular DL, embedding scalar numerical\nfeatures into a high-dimensional space before they are fed into the main backbone is beneficial. While\nnumerical embeddings have become an established design choice in the field, the reasons for their\neffectiveness are not entirely clear. In our paper, we reveal that an important property of numerical\nembeddings is their ability to handle high data uncertainty regions of data.\nFigure 6 demonstrates uncertainty plots for MLP vs MLP-PLR, where \u201c-PLR\u201d denotes periodic\nactivations followed by a linear layer with a ReLU nonlinearity as described in Gorishniy et al. (2022).\nHere we report the analysis on four datasets2:\n1.California Housing3, an established regression dataset, where numerical embeddings were\nshown to be beneficial (Gorishniy et al., 2022).\n2.Sberbank Housing (Rubachev et al., 2025), a recently introduced dataset with a temporal\ndistribution shift between its training and test subsets.\n3.Maps Routing (Rubachev et al., 2025), a large-scale dataset needed to demonstrate that our\nanalysis is valid for larger problems as well.\n4.Delivery ETA (Rubachev et al., 2025), a dataset where MLP-PLR underperforms MLP.\nDespite this, the model with embeddings still slightly outperforms the MLP baseline in the\nhigh data uncertainty region, while losing more in the lower data uncertainty niche.\n0.00.20.40.60.8\n\u22120.050.000.050.100.150.200.250.30\n\u22120.010.000.010.020.030.040.050.06\n0.00.10.20.30.40.5\nMSE MLP\n0 1000 2000 3000 4000\u22120.0250.0000.0250.0500.0750.1000.1250.150\u2206MSE =MSE MLP\u2212MSE MLP\u2212PLR\n\u2206MSEMSE MLPCalifornia Housing\n0 2000 40000.000.010.020.030.04\n\u2206MSEMSE MLPSberbank Housing\n0 20000 40000 600000.00000.00050.00100.00150.00200.0025\n\u2206MSEMSE MLPMaps Routing\n0 10000 20000 300000.0000.0050.0100.015\n\u2206MSEMSE MLPDelivery ETA\nLower Data Uncertainty \u2190Test Dataset Examples \u2192Higher Data Uncertainty\nFigure 6: Uncertainty plots report the differences in MSE between MLP and MLP-PLR. The increase\nin performance is the most significant in the high data uncertainty niche.\nThe main observation from Figure 6 is that numerical \u201c-PLR\u201d embeddings are disproportionately\nmore beneficial for high data uncertainty samples. Specifically, the difference in MSE grows faster\nwith data uncertainty than the value of MSE for the baseline MLP, which shows that numerical\nembeddings do not just proportionally improve performance for all levels of uncertainty, but do so\nmore in high data uncertainty region.\n5.1 W HY DO NUMERICAL EMBEDDINGS OUTPERFORM IN THE HIGH DATA UNCERTAINTY\nNICHE ?\nWhen using numerical embeddings, one maps the original datapoints into a higher-dimensional space\nthat effectively becomes a new input space for the main backbone. We claim that properly designed\nnumerical embeddings correspond to a space with higher local target consistency, i.e., the neighboring\npoints in this space are more likely to have similar targets. We demonstrate that behavior on several\ndatasets. Figure 7 reports the squared difference between the target of a test datapoint and the target of\nitsk-th closest neighbor from the training set (averaged over all test subset) for MLP and MLP-PLR\nmodels. We sort the neighbors by the Euclidean distance in the latent space obtained after the first\nblock of the model, to show the distance in the space that has already incorporated the signal from all\nfeatures and still comes relatively early in the model.\nWhile numerical embeddings improve the local target consistency in the neighborhoods of all\ndatapoints, this leads to disproportionate performance improvement on datapoints that have higher\n2Similar plots on other established datasets are reported in Appendix A.\n3https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n7\n\n--- Page 8 ---\nPreprint\n0 20 40 60 80 100\nk0.20.30.40.50.6Etest(yk\u2212ytest)2\nPLRNo EmbeddingsCalifornia Housing\n0 20 40 60 80 100\nk0.50.60.70.80.91.0\nPLRNo EmbeddingsHouse 16H\n0 20 40 60 80 100\nk0.040.050.060.070.080.090.10\nPLRNo EmbeddingsDiamond\nkclosest neighbor\u2192Distance increases left to right\nFigure 7: Squared difference between a test sample\u2019s target and the target of its k-th closest neighbor,\naveraged over the test set. The difference is smaller when using PLR embeddings.\ndata uncertainty, as shown in Figure 6. We explain this effect by the fact that the model\u2019s predictions\non high data uncertainty points rely on the quality of their neighborhoods more heavily. Figure 5\nconfirms our intuition on the synthetic task. For low data uncertainty regions (bottom), a simple MLP\nis able to model sharp separating planes between the predictions \u201c 0\u201d and \u201c 1\u201d. As data uncertainty\nincreases, the MLP predictions become smoother, until they become so smooth that the original\nsaw-like target structure becomes unnoticeable. This demonstrates that when MLP makes a prediction\non a high data uncertainty datapoint, it is more dependent on the datapoint\u2019s neighborhood, effectively\nperforming more \u201cconservative\u201d local target smoothing. As an additional illustration, Figure 5 shows\nthat the better representations provided by the learned LRLR embeddings lead to better predictions\neven at the levels where the original MLP predictions fail.\n5.2 A MORE EFFECTIVE EMBEDDING SCHEME\nTable 2: This table shows a comparison of the tuned\nMLP, the tuned MLP with LRLR embeddings and the\ntuned MLP with our proposed improved LRLR embed-\ndings trained to maximize local target consistency. We\nreport average percentage improvements over MLP and\naverage ranks across regression datasets from Grinsztajn\net al. (2022); Gorishniy et al. (2025). We can see that\nthe LRLR triplet embeddings substantially outperform the\nexisting alternatives. For full dataset-wise results, see\nAppendix G\nModel \u2206MLP (%) Avg. Rank\nMLP 0.00 2.75 (\u00b10.50)\nMLP-LRLR 2.00 (\u00b12.34) 1.67 (\u00b10.49)\nMLP-LRLR triplet 2.81 (\u00b12.54) 1.17 (\u00b10.51)While numerical embeddings proposed in\nGorishniy et al. (2022) substantially im-\nprove the quality of neighborhoods needed\nto handle high data uncertainty, they do\nnot explicitly aim for this behavior. In con-\ntrast, we propose a new numerical embed-\nding scheme that is learned by explicitly\nmaximizing the local target consistency. In\nmore detail, we train an embedder module\nthat produces a high-dimensional represen-\ntation of a given object. The architecture\nof our module consists of the \u201c-LRLR\u201d em-\nbedder described in Gorishniy et al. (2022),\nfollowed by a simple linear layer.\nWe train the embedder module using the\nstandard triplet loss (Schroff et al., 2015).\nMore specifically, we first randomly sam-\nple a batch of training objects that will\nserve as anchors in the triplet loss. Then, for each anchor object, we randomly sample a pair\nof other training objects, of which the one with the closer target becomes a positive example, and the\nother one becomes the negative example. We then compute the embeddings for all three objects with\nour embedder as well as two dot-product similarities: the first one is between the embeddings of the\nanchor and the positive example, and the second one is between the embeddings of anchor and the\nnegative example. We then pass these similarities as logits to the cross-entropy loss, for which the\ntarget is \u201c0\u201d. By doing this, we effectively force the model to learn closer representations for objects\nwith more similar targets.\nAfter pretraining the embedder, we discard its last linear layer and use its remaining part to initialize\nthe embedding part of the \u201cMLP-LRLR\u201d architecture. The exact hyperparameters used in our\nexperiments are provided in Appendix G.\n8\n\n--- Page 9 ---\nPreprint\nTable 2 demonstrates how our embedding scheme improves the performance in comparison with\nLRLR embeddings from Gorishniy et al. (2022) trained from scratch. Information regarding statistical\nsignificance, along with full results for each dataset, is provided in Appendix G.\n6 M ODERN NCA AND HIGH DATA UNCERTAINTY\nTo investigate the interplay between retrieval modules and data uncertainty, we focus on the Mod-\nernNCA model (Ye et al., 2024), which is a recent model that consists of an MLP-like backbone\nfollowed by a kNN-like prediction head. Figure 8 shows that compared to MLP, ModernNCA also\nimproves the performance on higher data uncertainty points, while the performance on lower data\nuncertainty points sometimes slightly decreases. We explain this by first noticing that averaging over\na large number of neighbors inherent to retrieval-augmented models leads to less overfitting on the\nhigh data uncertainty regions when compared to MLP.\n0 1000 2000 3000 4000\u22120.050.000.050.100.150.200.25\u2206MSE =MSE MLP\u2212MSE MNCACalifornia Housing\n0 1000 2000 3000 40000246\u00d7107 House 16H\n0 20000 40000 60000\u22120.00050.00000.00050.00100.00150.0020Maps Routing\n0 2000 4000 6000 8000 10000\u22120.00250.00000.00250.00500.00750.01000.0125Diamond\nLower Data Uncertainty \u2190Test Dataset Examples \u2192Higher Data Uncertainty\nFigure 8: Uncertainty plots, built in the same way as in Figure 1, but showing difference in MSE\nbetween MLP and ModernNCA. On House and Maps-Routing datasets, ModernNCA is inferior\nto MLP in the lower/medium data uncertainty niches, while on the other two datasets it shows\nimprovement in all niches of uncertainty.\nTo demonstrate this, in Figure 9 we report the sample-wise MSE loss of ModernNCA computed on\ntraining datapoints, where training datapoints are sorted in order of the increasing data uncertainty.\nFigure 9 shows that compared to MLP, ModernNCA severely undefits the data on high data uncertainty\nzone. On the one hand, this underfitting effect provides robustness to the noise in the train targets\nfor the high data uncertainty niche, since ModernNCA memorizes the noise in the data to a lesser\ndegree. On the other hand, on some datasets (e.g. Maps Routing, House), this excessive underfit can\nbe harmful to performance in the lower and medium data uncertainty niches.\n0 2500 5000 7500 10000 12500\u22121.0\u22120.8\u22120.6\u22120.4\u22120.20.0\u2206MSE =MSE MLP\u2212MSE MNCACalifornia Housing\n0 5000 10000 15000\u22123.0\u22122.5\u22122.0\u22121.5\u22121.0\u22120.50.0\u00d7109 House 16H\n0 50000 100000 150000\u22120.0020\u22120.0015\u22120.0010\u22120.00050.0000Maps Routing\n0 10000 20000 30000\u22120.05\u22120.04\u22120.03\u22120.02\u22120.010.00Diamond\nlower data uncertainty \u2190Train Dataset Examples \u2192higher data uncertainty\nFigure 9: Difference in MSE performance of MLP and ModernNCA on train samples, with samples\nsorted by increasing uncertainty. ModernNCA\u2019s higher loss demonstrates that it often produces overly\nsmooth predictions, underfitting the data, for example in Figure 5.\n7 E NSEMBLING AND HIGH DATA UNCERTAINTY\nThe recent TabM model (Gorishniy et al., 2025) also demonstrates a more significant improvement on\nhigher data uncertainty datapoints, as shown in Figure 10. Interestingly, while TabM was described\nas an efficient ensemble, traditional deep ensemble demonstrates inferior performance, which is\nespecially noticeable in high data uncertainty regions. Another illustration of the differences between\nTabM and ensemble is shown by our synthetic example described in subsection 4.2. While deep\n9\n\n--- Page 10 ---\nPreprint\n0 1000 2000 3000 40000.0000.0250.0500.0750.1000.1250.1500.175\u2206MSE =MSE MLP\u2212MSE Model\n\u2206MSE TabM\n\u2206MSE EnsembleCalifornia Housing\n0 1000 2000 3000 400001234\u00d7108\n\u2206MSE TabM\n\u2206MSE EnsembleHouse 16H\n0 20000 40000 600000.00000.00050.00100.00150.00200.00250.00300.0035\n\u2206MSE TabM\n\u2206MSE EnsembleMaps Routing\n0 10000 20000 30000 400000.00.10.20.30.4\u2206MSE TabM\n\u2206MSE EnsembleWeather\nLower Data Uncertainty \u2190Test Dataset Examples \u2192Higher Data Uncertainty\nFigure 10: The plots show sample-wise differences in MSE between MLP and TabM in blue and\nsample-wise differences in MSE between MLP and a Deep Ensemble of MLPs in brown, with samples\nsorted by increasing data uncertainty. TabM shows substantially higher performance, especially on\nhigh data uncertainty regions.\nensemble shows almost no difference in performance compared to a single MLP, TabM learns a\nfunction much better representing the underlying noiseless target distribution.\nIn this section, we explain the reason behind the robustness of TabM to noise in the targets compared\nto a deep ensemble. Below, we demonstrate that this stems from the fact that the averaging of the\ngradients for shared parameters of TabM effectively reduces the noise in the gradients from individual\nbranches.\n0 2000 4000 6000 8000 100000.51.01.52.02.5Ratio of L2 norms of clean and noisy components of \u2207\nclean / noisy ratio for TabM\nclean / noisy ratio for MLP\nlower data uncertainty \u2190Test Dataset Examples \u2192higher data uncertainty\nFigure 11: The plot shows ratios of the norms of\nclean and noisy components of the gradient for\nTabM and MLP for the synthetic dataset from\nsubsection 4.2. In this experiment, both mod-\nels were tuned and trained. Data uncertainty\nincreases from left to right. The ratio grows with\nincreasing data uncertainty more for TabM until\nit reaches a point in data uncertainty where both\nmodels fail; after that it starts moving towards\nthe value of MLP\u2019s clean-to-noisy ratio.\n0 2000 4000 6000 8000 100000.30.40.50.60.7Norm of avg. \u2207divided by avg. norm of \u2207across branches\nNoisy component\nClean component\nlower data uncertainty \u2190Test Dataset Examples \u2192higher data uncertaintyFigure 12: The plot shows the ratio of the aver-\nage norm of a per-branch gradient to a norm of\nthe gradient averaged between branches, taken\nseparately for clean and noisy components. In\nthis experiment, TabM model was tuned and\ntrained. Higher value shows alignment between\nthe individual gradients. The ratio grows with in-\ncreasing data uncertainty more for the clean com-\nponent, until it reaches a point in data uncertainty\nwhere TabM fails, after which it approaches the\nratio for the noisy part of the gradients.\nFirst, let us decompose the model\u2019s gradient for a particular datapoint into a \u201cclean\u201d component and\na \u201cnoisy\u201d component. We denote the model as a function \u03d5(\u00b7)and denote the model weights as \u03b8.\nAs described in subsection 4.2, the target values yiare comprised of the noiseless part and the noisy\ntermyi=f(xi) +eg(xi)\u00b7 N(0,1). Therefore,\n\u2202(\u03d5(xi)\u2212yi)2\n\u2202\u03b8= 2(\u03d5(xi)\u2212yi)\u2202\u03d5(xi)\n\u2202\u03b8= 2(\u03d5(xi)\u2212f(xi)\u2212eg(xi)\u00b7 N(0,1))\u2202\u03d5(xi)\n\u2202\u03b8=\n= 2(\u03d5(xi)\u2212f(xi))\u2202\u03d5(xi)\n\u2202\u03b8\u22122eg(xi)\u00b7 N(0,1)\u00b7\u2202\u03d5(xi)\n\u2202\u03b8(2)\nIn this subtraction, the first term corresponds to the gradient of the noiseless part of the target\ndependency f(\u00b7). The second term corresponds to the noisy component of the gradient. Both terms\n10\n\n--- Page 11 ---\nPreprint\ncan be explicitly computed for the synthetic data from subsection 4.2, since both f(\u00b7)andg(\u00b7)are\nknown.\nFor robust training on noisy data, it is beneficial to minimize the noisy component of the gradients\nto make overall gradients as close to their noiseless components as possible. We argue that the\ncontribution from the noisy components to the overall gradients is much lower in TabM compared to\nMLP. To illustrate this, in Figure 11, we show that the ratio of L2 norms of clean and noisy gradient\ncomponents is much higher in TabM than in MLP, indicating that the noisy gradients affect TabM\u2019s\nlearning process to a lesser extent.\nWe explain this difference by averaging of the gradients obtained from different branches in TabM.\nTo confirm this explanation, we compute the ratio of the norm of averaged gradients to the average\nnorm of gradient of the individual branches (for both the noisy and clean gradient components). In\nFigure 12, we report this ratio and show that the averaging reduces the norm of the noisy part more\nsubstantially than that of the clean part.\nThis behavior makes TabM more reluctant to learn noisy parts of the target dependency, which leads\nto better performance in the high data uncertainty region.\n8 C ONCLUSION\nIn this paper, we propose an uncertainty-centric lens to investigate tabular DL approaches. This\nunifying perspective serves a dual purpose: it elucidates the strengths and limitations of various\nrecent techniques and directly informs the development of a more effective scheme for embedding\nnumerical features. Looking ahead, an interesting avenue for future research involves extending\nthis uncertainty-driven analysis to the growing field of tabular foundational models (Hollmann et al.,\n2025).\n9 L IMITATIONS\nSeveral limitations should be acknowledged in this work. Our investigation was primarily focused\non regression tasks; future research could extend this analysis to include classification problems.\nFurthermore, to maintain a specific focus on tabular DL approaches, we deliberately excluded\nthe examination of general-purpose deep learning mechanisms (e.g., dropout, weight decay, robust\noptimizers). Lastly, although knowledge uncertainty presents an important and potentially informative\nviewpoint, its detailed exploration was not a central objective of the current study.\nREFERENCES\nBaek, C., Kolter, Z., and Raghunathan, A. Why is sam robust to label noise? In ICLR , 2024.\nBahri, D., Jiang, H., Tay, Y ., and Metzler, D. SCARF: Self-supervised contrastive learning using\nrandom feature corruption. In ICLR , 2021.\nChen, T. and Guestrin, C. XGBoost: A scalable tree boosting system. In SIGKDD , 2016.\nDuan, T., Anand, A., Ding, D. Y ., Thai, K. K., Basu, S., Ng, A., and Schuler, A. Ngboost: Natural\ngradient boosting for probabilistic prediction. In International conference on machine learning , pp.\n2690\u20132700. PMLR, 2020.\nGal, Y . et al. Uncertainty in deep learning. phd thesis, University of Cambridge , 2016.\nGorishniy, Y ., Rubachev, I., Khrulkov, V ., and Babenko, A. Revisiting deep learning models for\ntabular data. In NeurIPS , 2021.\nGorishniy, Y ., Rubachev, I., and Babenko, A. On embeddings for numerical features in tabular deep\nlearning. In NeurIPS , 2022.\nGorishniy, Y ., Rubachev, I., Kartashev, N., Shlenskii, D., Kotelnikov, A., and Babenko, A. TabR:\nTabular deep learning meets nearest neighbors. In ICLR , 2024.\n11\n\n--- Page 12 ---\nPreprint\nGorishniy, Y ., Kotelnikov, A., and Babenko, A. Tabm: Advancing tabular deep learning with\nparameter-efficient ensembling. In ICLR , 2025.\nGrinsztajn, L., Oyallon, E., and Varoquaux, G. Why do tree-based models still outperform deep\nlearning on typical tabular data? In NeurIPS, the \"Datasets and Benchmarks\" track , 2022.\nHollmann, N., M\u00fcller, S., Eggensperger, K., and Hutter, F. TabPFN: A transformer that solves small\ntabular classification problems in a second. In ICLR , 2023.\nHollmann, N., M\u00fcller, S., Purucker, L., Krishnakumar, A., K\u00f6rfer, M., Hoo, S. B., Schirrmeister,\nR. T., and Hutter, F. Accurate predictions on small data with a tabular foundation model. Nature ,\n637(8045):319\u2013326, 2025.\nHolzm\u00fcller, D., Grinsztajn, L., and Steinwart, I. Better by default: Strong pre-tuned mlps and boosted\ntrees on tabular data. In The Thirty-eighth Annual Conference on Neural Information Processing\nSystems , 2024.\nJeffares, A., Liu, T., Crabb\u00e9, J., Imrie, F., and van der Schaar, M. TANGOS: Regularizing tabular\nneural networks through gradient orthogonalization and specialization. In ICLR , 2023.\nKe, G., Meng, Q., Finley, T., Wang, T., Chen, W., Ma, W., Ye, Q., and Liu, T.-Y . LightGBM: A highly\nefficient gradient boosting decision tree. Advances in neural information processing systems , 30:\n3146\u20133154, 2017.\nKrizhevsky, A., Hinton, G., et al. Learning multiple layers of features from tiny images.(2009), 2009.\nMalinin, A., Prokhorenkova, L., and Ustimenko, A. Uncertainty in gradient boosting via ensembles.\nInICLR , 2021.\nMcElfresh, D., Khandagale, S., Valverde, J., Prasad C, V ., Ramakrishnan, G., Goldblum, M., and\nWhite, C. When do neural nets outperform boosted trees on tabular data? Advances in Neural\nInformation Processing Systems , 36:76336\u201376369, 2023.\nProkhorenkova, L., Gusev, G., V orobev, A., Dorogush, A. V ., and Gulin, A. CatBoost: unbiased\nboosting with categorical features. In NeurIPS , 2018.\nRubachev, I., Alekberov, A., Gorishniy, Y ., and Babenko, A. Revisiting pretraining objectives for\ntabular deep learning. arXiv , 2207.03208v1, 2022.\nRubachev, I., Kartashev, N., Gorishniy, Y ., and Babenko, A. TabReD: Analyzing Pitfalls and Filling\nthe Gaps in Tabular Deep Learning Benchmarks. In arXiv , 2025.\nSchroff, F., Kalenichenko, D., and Philbin, J. Facenet: A unified embedding for face recognition and\nclustering. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition\n(CVPR) , June 2015.\nSomepalli, G., Goldblum, M., Schwarzschild, A., Bruss, C. B., and Goldstein, T. SAINT: improved\nneural networks for tabular data via row attention and contrastive pre-training. arXiv , 2106.01342v1,\n2021.\nTanaka, D., Ikami, D., Yamasaki, T., and Aizawa, K. Joint optimization framework for learning with\nnoisy labels, 2018. URL https://arxiv.org/abs/1803.11364 .\nThimonier, H., Costa, J. L. D. M., Popineau, F., Rimmel, A., and Doan, B.-L. T-jepa: Augmentation-\nfree self-supervised learning for tabular data. In ICLR , 2024.\nTschalzev, A., Purucker, L., L\u00fcdtke, S., Hutter, F., Bartelt, C., and Stuckenschmidt, H. Unreflected\nuse of tabular data repositories can undermine research quality. arXiv preprint arXiv:2503.09159 ,\n2025.\nYe, H.-J., Yin, H.-H., and Zhan, D.-C. Modern neighborhood components analysis: A deep tabular\nbaseline two decades later. arXiv , 2407.03257v1, 2024.\n12\n\n--- Page 13 ---\nPreprint\nA U NCERTAINTY PLOTS FOR OTHER DATASETS\nIn this section we provide the uncertainty plots for all regression datasets from the Rubachev et al.\n(2025) and Gorishniy et al. (2021) benchmarks. In the main text we report the most informative plots\nthat clearly illustrate our observations. The uncertainty plots for all models on all datasets are in\nFigure 13 and Figure 14.\n0 1000 2000 3000 40000.000.050.100.150.200.25\u2206MSE =MSE MLP\u2212MSE ModelCalifornia Housing\nTabM\nDeep Ensemble\nMLP-PLR\nModernNCA\nXGBoost\n0 2000 40000.00.51.01.52.02.53.03.5\u00d7108House 16H\n0 2500 5000 7500 100000.00000.00250.00500.00750.01000.01250.0150Diamond\n0 10000 20000 300000.000.010.020.030.040.05Black Friday\n0 100000 2000000.000.010.020.030.040.050.060.07Microsoft\nLower Data Uncertainty \u2190Test Dataset Examples \u2192Higher Data Uncertainty\nFigure 13: Uncertainty plots depicting differences between MLP and XGBoost, Deep Ensemble,\nMLP-PLR, ModernNCA and TabM.\n0 2000 4000\u22120.02\u22120.010.000.010.020.030.040.05\u2206MSE =MSE MLP\u2212MSE ModelSberbank Housing\nTabM\nDeep Ensemble\nMLP-PLR\nModernNCA\nXGBoost\n0 20000 40000 60000\u22120.0010.0000.0010.0020.003Maps Routing\n0 20000 40000\u22120.20.00.20.40.6Weather\n0 20000 40000\u22120.0050\u22120.00250.00000.00250.00500.00750.01000.0125Cooking Time\n0 20000\u22120.0020.0000.0020.0040.0060.008Delivery ETA\nLower Data Uncertainty \u2190Test Dataset Examples \u2192Higher Data Uncertainty\nFigure 14: Uncertainty plots depicting differences between MLP and XGBoost, Deep Ensemble,\nMLP-PLR, ModernNCA and TabM. The Cooking Time dataset is an exception to our analysis, which\nwe believe stems from the failure of data uncertainty estimation on this dataset.\nB T ECHNICAL DETAILS REGARDING UNCERTAINTY PLOTS\nTo estimate data uncertainty, we use CatBoost with the RMSEWithUncertainty loss function. Then,\nwe sort the test datapoints in ascending order based on their estimated data uncertainty values, and\ncalculate the difference in MSE between two models for each datapoint. Finally, we apply gaussian\nsmoothing, using function gaussial_filter1d from scipy library.\nC T ECHNICAL DETAILS REGARDING HYPERPARAMETER TUNING FOR\nMODELS IN EMPIRICAL EXPERIMENTS\nIn this section we describe the hyperparameter spaces that were used to tune model hyperparameters\nin the experiments.\nFor the TabM model, we use the default TabM model from the reference implementation and follow\nGorishniy et al. (2025) tuning spaces. For ModernNCA, MLP and MLP-PLR we also follow the\ntuning spaces from Gorishniy et al. (2025), except using powers of two for the neural network width\ntuning. For the exact tuning spaces and best parameters see the source code provided with the\nsubmission.\n13\n\n--- Page 14 ---\nPreprint\nD T ECHNICAL DETAILS REGARDING A SYNTHETIC SAW -LIKE DATASET\nThe exact algorithm used for the generation of the dataset is provided in the code. Generally speaking,\nwe uniformly sample points from (0, 0) to (1, 10), and then set the target value as 1 inside the triangles\nwith vertices (2i,0),(2i+ 1,1),(2i+ 2,0), for values of i: 0,1,2,3,4. We also add the random\nnormal noise to the targets, with the standard deviation of the noise set tox6\n1\n4, forx1from 0 to 10.\nETECHNICAL DETAILS REGARDING HYPERPARAMETER TUNING FOR MODELS\nON SYNTHETIC DATASETS\nHere we describe the technical details regarding hyperparameter tuning for synthetic datasets.\nSaw-like synthetic data . For this experiment we keep all model-architecture hyperparameters fixed\nat reasonable default values (3 layers, hidden dimension is 256, dropout is 0.2, 16 branches for\nTabM, dimension of embedding is 64 for MLP-LRLR) and only tune the learning rates, except the\nModernNCA model for which we also tune the architecture hyperparameters. Details regarding\ntuning, early-stopping and other training protocols follow the one described in Appendix C.\nSynthetic data from the section 5 on numerical embeddings . For this dataset we tune the MLP-PLR\nmodel using the same protocol that is described in Appendix C.\nFTECHNICAL DETAILS REGARDING SYNTHETIC DATASET WITH f(\u00b7)AND g(\u00b7)\nPARAMETERIZED WITH MLP S\nWe generate this dataset as follows. First, we sample 40000 20-dimentional standard normal vectors.\nThen, we employ two MLPs to parametrize functions f(\u00b7)andg(\u00b7). The MLP simulating function\nf(\u00b7)consists of three linear layers separated by ReLU activations. The MLP simulating function g(\u00b7)\nconsists of two linear layers separated by a ReLU activation, with hidden dimension being equal to\n10. We generate yiasf(xi) +g(xi)\u00b7 N(0,1).\nG T ECHNICAL DETAILS REGARDING MORE EFFECTIVE EMBEDDINGS\nLEARNING AND HYPERPARAMETER TUNING\nIn this section we provide the hyperparameter tuning spaces for the more effective numerical features\nembeddings proposed in section 5. The tuning space is presented in Table 3.\nTable 3: The hyperparameter tuning space for the MLP and MLP-LRLR.\nParameter Distribution\n# layers UniformInt[1 ,4]\nWidth (hidden size) PowersOfTwo[27,211]\nDropout rate {0.0,Uniform[0 .0,0.75]}\nWeight decay*{0,LogUniform[1 e-6,1e-3]}\nLearning rate*LogUniform[3 e-5,1e-3]\n* \u2013 We decouple optimizer parameters for the triplet pretraining and finetuning phases.\nEmbedding Parameters (for LRLR and LRLR triplet)\nd_embedding {64,128}\n# Tuning iterations 100\nThe code for reproducing the results for the more effective embedding scheme with triplet-loss based\npretraining is available in the supplementary materials. In Table 4 we provide all unaggregated results\non the regression datasets from the Gorishniy et al. (2025) benchmark no larger than 50K samples.\nWe also exclude two problematic datasets reported by Tschalzev et al. (2025). When computing\n14\n\n--- Page 15 ---\nPreprint\nranks for the aggregations above we use code provided with the supplementary materials that uses\nstandard deviations to account for the statistical significance of the ranking.\nTable 4: Extended results for the main benchmark. Results are grouped by datasets.\nAilerons \u2193\nMethod Single model Ensemble\nMLP 0.0002\u00b10.0000 0 .0002\u00b10.0000\nMLP-LRLR 0.0002\u00b10.0000 0 .0002\u00b10.0000\nMLP-LRLR triplet 0.0002\u00b10.0000 0 .0002\u00b10.0000MiamiHousing2016 \u2193\nMethod Single model Ensemble\nMLP 0.1604\u00b10.0029 0 .1561\u00b10.0026\nMLP-LRLR 0.1507\u00b10.0028 0 .1483\u00b10.0032\nMLP-LRLR triplet 0.1471\u00b10.0023 0 .1445\u00b10.0018\nOnlineNewsPopularity \u2193\nMethod Single model Ensemble\nMLP 0.8635\u00b10.0007 0 .8622\u00b10.0003\nMLP-LRLR 0.8595\u00b10.0010 0 .8568\u00b10.0003\nMLP-LRLR triplet 0.8581\u00b10.0010 0 .8557\u00b10.0005analcatdata_supreme \u2193\nMethod Single model Ensemble\nMLP 0.0781\u00b10.0097 0 .0762\u00b10.0090\nMLP-LRLR 0.0775\u00b10.0077 0 .0762\u00b10.0080\nMLP-LRLR triplet 0.0774\u00b10.0088 0 .0766\u00b10.0093\ncalifornia \u2193\nMethod Single model Ensemble\nMLP 0.4940\u00b10.0048 0 .4848\u00b10.0015\nMLP-LRLR 0.4628\u00b10.0024 0 .4536\u00b10.0019\nMLP-LRLR triplet 0.4582\u00b10.0032 0 .4494\u00b10.0011cpu_act \u2193\nMethod Single model Ensemble\nMLP 2.7117\u00b10.1624 2 .5668\u00b10.1102\nMLP-LRLR 2.2692\u00b10.0676 2 .1990\u00b10.0698\nMLP-LRLR triplet 2.2782\u00b10.1183 2 .2019\u00b10.0979\ndiamond \u2193\nMethod Single model Ensemble\nMLP 0.1396\u00b10.0012 0 .1370\u00b10.0006\nMLP-LRLR 0.1342\u00b10.0013 0 .1324\u00b10.0008\nMLP-LRLR triplet 0.1328\u00b10.0010 0 .1321\u00b10.0004elevators \u2193\nMethod Single model Ensemble\nMLP 0.0020\u00b10.0000 0 .0019\u00b10.0000\nMLP-LRLR 0.0018\u00b10.0000 0 .0018\u00b10.0000\nMLP-LRLR triplet 0.0018\u00b10.0000 0 .0018\u00b10.0000\nfifa\u2193\nMethod Single model Ensemble\nMLP 0.8025\u00b10.0135 0 .8005\u00b10.0149\nMLP-LRLR 0.7880\u00b10.0114 0 .7849\u00b10.0122\nMLP-LRLR triplet 0.7863\u00b10.0112 0 .7836\u00b10.0124house \u2193\nMethod Single model Ensemble\nMLP 3.1105\u00b10.0439 3 .0385\u00b10.0390\nMLP-LRLR 3.1181\u00b10.0568 3 .0434\u00b10.0354\nMLP-LRLR triplet 3.0705\u00b10.0156 3 .0470\u00b10.0078\nhouse_sales \u2193\nMethod Single model Ensemble\nMLP 0.1812\u00b10.0009 0 .1781\u00b10.0004\nMLP-LRLR 0.1677\u00b10.0005 0 .1660\u00b10.0002\nMLP-LRLR triplet 0.1696\u00b10.0006 0 .1677\u00b10.0001isolet \u2193\nMethod Single model Ensemble\nMLP 2.2740\u00b10.3170 2 .0363\u00b10.1421\nMLP-LRLR 2.3179\u00b10.1404 2 .1286\u00b10.0940\nMLP-LRLR triplet 2.3119\u00b10.1506 2 .1873\u00b10.1349\nparticulate-matter-ukair-2017 \u2193\nMethod Single model Ensemble\nMLP 0.3779\u00b10.0006 0 .3754\u00b10.0002\nMLP-LRLR 0.3661\u00b10.0009 0 .3634\u00b10.0002\nMLP-LRLR triplet 0.3652\u00b10.0006 0 .3629\u00b10.0002pol\u2193\nMethod Single model Ensemble\nMLP 5.6147\u00b10.6212 5 .1092\u00b10.6127\nMLP-LRLR 2.6721\u00b10.1627 2 .4205\u00b10.1062\nMLP-LRLR triplet 2.5144\u00b10.1259 2 .3130\u00b10.0560\n15\n\n--- Page 16 ---\nPreprint\nsberbank-housing \u2193\nMethod Single model Ensemble\nMLP 0.2508\u00b10.0046 0 .2447\u00b10.0019\nMLP-LRLR 0.2427\u00b10.0054 0 .2383\u00b10.0014\nMLP-LRLR triplet 0.2405\u00b10.0084 0 .2323\u00b10.0013superconduct \u2193\nMethod Single model Ensemble\nMLP 10.7537\u00b10.0778 10 .3687\u00b10.0162\nMLP-LRLR 10.7919\u00b10.1539 10 .3938\u00b10.0130\nMLP-LRLR triplet 10.6695\u00b10.0817 10 .3082\u00b10.0451\nwine_quality \u2193\nMethod Single model Ensemble\nMLP 0.6682\u00b10.0139 0 .6573\u00b10.0153\nMLP-LRLR 0.6717\u00b10.0155 0 .6510\u00b10.0170\nMLP-LRLR triplet 0.6770\u00b10.0212 0 .6608\u00b10.0229year \u2193\nMethod Single model Ensemble\nMLP 8.9732\u00b10.0237 8 .8923\u00b10.0058\nMLP-LRLR 8.9511\u00b10.0190 8 .9168\u00b10.0059\nMLP-LRLR triplet 8.9398\u00b10.0095 8 .9246\u00b10.0042\nH C ONSISTENCY OF THE PROVIDED RESULTS WHEN USING DIFFERENT\nMODELS USED FOR DATA UNCERTAINTY ESTIMATION\nIn this section, we demonstrate that results we obtained in section 5, section 6 and section 7 stay the\nsame when using different models for uncertainty estimation.\nAs can be seen on Figure 15, Figure 16, Figure 17, Figure 18, Figure 19, Figure 20, our analysis is\nnot dependent on which specific model we use to estimate data uncertainty.\n0.000.250.500.751.001.25\n\u22120.050.000.050.100.150.200.250.30\n\u22120.010.000.010.020.030.040.050.06\n0.00.10.20.30.40.5\nMSE MLP\n0 1000 2000 3000 40000.000.050.100.150.20\u2206MSE =MSE MLP\u2212MSE MLP\u2212PLR\n\u2206MSEMSE MLPCalifornia Housing\n0 2000 40000.000.010.020.030.04\n\u2206MSEMSE MLPSberbank Housing\n0 20000 40000 600000.00000.00050.00100.0015\n\u2206MSEMSE MLPMaps Routing\n0 10000 20000 300000.0000.0050.0100.0150.0200.025\n\u2206MSEMSE MLPDelivery ETA\nLower Data Uncertainty \u2190Test Dataset Examples \u2192Higher Data Uncertainty\nFigure 15: Version of Figure 6, but using MLP as a basic model for estimating data uncertainty. As\ncan be seen, using different model for estimation leads to the same conclusion.\n0.00.20.40.60.81.0\n\u22120.050.000.050.100.150.200.250.30\n\u22120.010.000.010.020.030.040.050.06\n0.00.10.20.30.40.5\nMSE MLP\n0 1000 2000 3000 40000.0000.0250.0500.0750.1000.125\u2206MSE =MSE MLP\u2212MSE MLP\u2212PLR\n\u2206MSEMSE MLPCalifornia Housing\n0 2000 40000.000.010.020.030.04\n\u2206MSEMSE MLPSberbank Housing\n0 20000 40000 600000.00000.00050.00100.00150.00200.0025\n\u2206MSEMSE MLPMaps Routing\n0 10000 20000 300000.0000.0050.0100.0150.020\n\u2206MSEMSE MLPDelivery ETA\nLower Data Uncertainty \u2190Test Dataset Examples \u2192Higher Data Uncertainty\nFigure 16: Version of Figure 6, but using MLP-PLR as a basic model for estimating data uncertainty.\nAs can be seen, using different model for estimation leads to the same conclusion.\n16\n\n--- Page 17 ---\nPreprint\n0 1000 2000 3000 4000\u22120.050.000.050.100.150.20\u2206MSE =MSE MLP\u2212MSE MNCACalifornia Housing\n0 1000 2000 3000 4000\u22120.20.00.20.40.60.81.0\u00d7108 House 16H\n0 20000 40000 600000.00000.00050.00100.0015Maps Routing\n0 2000 4000 6000 8000 100000.0000.0020.0040.006Diamond\nLower Data Uncertainty \u2190Test Dataset Examples \u2192Higher Data Uncertainty\nFigure 17: Version of Figure 8, but using MLP as a basic model for estimating data uncertainty. As\ncan be seen, using different model for estimation leads to the same conclusion.\n0 1000 2000 3000 4000\u22120.050.000.050.100.150.20\u2206MSE =MSE MLP\u2212MSE MNCACalifornia Housing\n0 1000 2000 3000 4000\u22120.20.00.20.40.60.81.0\u00d7108 House 16H\n0 20000 40000 600000.00000.00050.00100.0015Maps Routing\n0 2000 4000 6000 8000 10000\u22120.0020.0000.0020.0040.0060.008Diamond\nLower Data Uncertainty \u2190Test Dataset Examples \u2192Higher Data Uncertainty\nFigure 18: Version of Figure 8, but using MLP-PLR as a basic model for estimating data uncertainty.\nAs can be seen, using different model for estimation leads to the same conclusion.\n0 1000 2000 3000 40000.000.050.100.15\u2206MSE =MSE MLP\u2212MSE Model\n\u2206MSE TabM\n\u2206MSE EnsembleCalifornia Housing\n0 1000 2000 3000 400001234\u00d7108\n\u2206MSE TabM\n\u2206MSE EnsembleHouse 16H\n0 20000 40000 600000.00000.00050.00100.00150.00200.0025\u2206MSE TabM\n\u2206MSE EnsembleMaps Routing\n0 10000 20000 30000 400000.000.050.100.150.200.250.30\u2206MSE TabM\n\u2206MSE EnsembleWeather\nLower Data Uncertainty \u2190Test Dataset Examples \u2192Higher Data Uncertainty\nFigure 19: Version of Figure 10, but using MLP as a basic model for estimating data uncertainty. As\ncan be seen, using different model for estimation leads to the same conclusion.\n0 1000 2000 3000 40000.000.050.100.15\u2206MSE =MSE MLP\u2212MSE Model\n\u2206MSE TabM\n\u2206MSE EnsembleCalifornia Housing\n0 1000 2000 3000 400001234\u00d7108\n\u2206MSE TabM\n\u2206MSE EnsembleHouse 16H\n0 20000 40000 600000.00000.00050.00100.00150.00200.00250.0030\u2206MSE TabM\n\u2206MSE EnsembleMaps Routing\n0 10000 20000 30000 400000.00.10.20.3\u2206MSE TabM\n\u2206MSE EnsembleWeather\nLower Data Uncertainty \u2190Test Dataset Examples \u2192Higher Data Uncertainty\nFigure 20: Version of Figure 10, but using MLP-PLR as a basic model for estimating data uncertainty.\nAs can be seen, using different model for estimation leads to the same conclusion.\n17",
  "project_dir": "artifacts/projects/enhanced_cs.LG_2509.04430v1_Unveiling_the_Role_of_Data_Uncertainty_in_Tabular_",
  "communication_dir": "artifacts/projects/enhanced_cs.LG_2509.04430v1_Unveiling_the_Role_of_Data_Uncertainty_in_Tabular_/.agent_comm",
  "assigned_at": "2025-09-06T20:42:07.326007",
  "status": "assigned"
}